# mini-shazam
Our project draws inspiration from the famous app Shazam and aims to recreate its core functionality using the GTZAN dataset and various machine learning algorithms. Through our project, we seek to explore the fundamental aspects of audio signal processing, feature extraction, and classification techniques to study, classify, and even recommend music based on audio inputs. Our goal is to develop a user-friendly interface that allows users to upload audio files and get accurate and fast results for identifying songs and discovering new music.
## Exploratory Data Analysis

To help users explore the data, we created a Gradio interface that displays various graphs related to the audio signal. To use the interface, follow these steps:

1. Clone the repository and install the data.
2. Open the EDA notebook using google colab.
3. Run all the cells and click on the gradio link
4. Upload an audio file in WAV format.
5. Select the type of graph you want to display from the dropdown menu.
6. The interface will display the selected graph and related statistics.

Here's what the interface looks like in action:

![Gradio Interface](EDA.gif)
